import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models
from torch.profiler import ProfilerActivity, profile, record_function, schedule
from torch.utils.data import DataLoader, Dataset

# ==========================================
# 1. åœºæ™¯è®¾ç½®ï¼šç°ä»£ CNN + æ¨¡æ‹Ÿçš„æ•°æ®ç“¶é¢ˆ
# ==========================================


class SyntheticImageDataset(Dataset):
    def __init__(self, size=5000):
        self.size = size
        # é¢„å…ˆç”Ÿæˆä¸€äº›éšæœºæ•°æ®
        self.data = torch.randn(size, 3, 224, 224)
        self.labels = torch.randint(0, 1000, (size,))

    def __len__(self):
        return self.size

    def __getitem__(self, idx):
        # [æ¨¡æ‹Ÿç“¶é¢ˆ]ï¼š
        # åœ¨è¿™é‡Œæˆ‘ä»¬ä¸åŠ  time.sleepï¼Œè€Œæ˜¯é€šè¿‡è®¾ç½® DataLoader çš„ num_workers=0
        # ä¸” batch_size è¾ƒå°ï¼Œæ¥æ¨¡æ‹Ÿ CPU å¤„ç†/è°ƒåº¦è·Ÿä¸ä¸Š GPU çš„æƒ…å†µã€‚
        # ç°ä»£ GPU (å¦‚ 3090/4090/A100) è·‘ ResNet18 éå¸¸å¿«ï¼Œææ˜“å‡ºç°è¿™ç§ç“¶é¢ˆã€‚
        return self.data[idx], self.labels[idx]


def modern_profiling_experiment():
    device = torch.device("cuda")

    # ä½¿ç”¨æ ‡å‡†çš„ ResNet18
    model = models.resnet18().to(device)
    optimizer = optim.SGD(model.parameters(), lr=0.01)
    criterion = nn.CrossEntropyLoss()

    # batch_size=32 å¯¹äº ResNet18 æ¥è¯´å¾ˆå°ï¼Œä¼šè®© GPU ç®—å¾—é£å¿«ï¼Œç„¶åç­‰å¾…ä¸‹ä¸€æ‰¹æ•°æ®
    dataset = SyntheticImageDataset()
    dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)

    print("ğŸš€ å¼€å§‹ç°ä»£åŒ– Profiling (PyTorch Kineto)...")

    # ==========================================
    # 2. ç°ä»£ Profiler é…ç½®
    # ==========================================
    # schedule: è‡ªåŠ¨ç®¡ç† warmup, active å‘¨æœŸï¼Œé¿å…åˆ†æå™¨æœ¬èº«çš„å¼€é”€å½±å“ç»“æœ
    my_schedule = schedule(skip_first=1, wait=1, warmup=1, active=3, repeat=1)

    with profile(
        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
        schedule=my_schedule,
        on_trace_ready=torch.profiler.tensorboard_trace_handler("./log/modern_test"),
        record_shapes=True,
        profile_memory=True,
        with_stack=True,  # æ•æ‰ Python ä»£ç å †æ ˆï¼Œæ–¹ä¾¿å®šä½æ˜¯å“ªè¡Œä»£ç å¡ä½äº†
    ) as p:
        for step, (inputs, targets) in enumerate(dataloader):
            if step >= 6:
                break  # åªéœ€è¦è·‘å‡ ä¸ª step å³å¯

            with record_function("Data_Transfer_H2D"):  # æ‰‹åŠ¨æ‰“æ ‡ç­¾ï¼Œæ–¹ä¾¿åœ¨å›¾ä¸­è¯†åˆ«
                inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)

            with record_function("Model_Forward"):
                outputs = model(inputs)
                loss = criterion(outputs, targets)

            with record_function("Model_Backward"):
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

            p.step()  # é€šçŸ¥ profiler è¿›å…¥ä¸‹ä¸€é˜¶æ®µ

    print("âœ… Profiling å®Œæˆã€‚æ•°æ®å·²ä¿å­˜è‡³ ./log/modern_test")
    print("è¯·æŒ‰ç…§ä¸‹æ–‡æŒ‡å¼•ä½¿ç”¨ Perfetto è¿›è¡Œå¯è§†åŒ–åˆ†æã€‚")


if __name__ == "__main__":
    modern_profiling_experiment()
